# PCA_Numerical

This repository demonstrates the **Principal Component Analysis (PCA)** technique through a detailed numerical approach. It breaks down PCA into fundamental steps for understanding dimensionality reduction.

### Step-by-Step Implementation:
1. **Insert Data**: Load the dataset.
2. **Mean Centering**: Subtract the mean from each dimension.
3. **Covariance Matrix**: Compute the covariance matrix of the data.
4. **Eigenvalues and Eigenvectors**: 
   - Compute eigenvalues using numerical methods.
   - Derive eigenvectors corresponding to the eigenvalues.
5. **Variance Analysis**:
   - Calculate the variance explained by each principal component.
   - Visualize eigenvector directions and explained variance.
6. **Dimensionality Reduction**:
   - Project data onto principal components.
   - Reduce dimensions while retaining maximum variance.

### Example Result:
- Convert 2D data into 1D representation while preserving **96% of the variance**.
  - Open the Jupyter Notebook for code:
    [PCA_Numerical.ipynb](https://github.com/shrijak/PCA_Numerical/blob/main/PCA_Numerical.ipynb)
  - Open the PDF for a basic explanation:
    [2) PCA Numerical.pdf](https://github.com/shrijak/PCA_Numerical/blob/main/2\)%20PCA%20Numerical.pdf)
